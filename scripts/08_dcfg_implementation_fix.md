# 슬라이드 8: D-CFG: 똑똑한 구현 전략

**(슬라이드 전환 후 잠시 멈춤)**

---

### **문제 해결의 핵심: 전체 대신 부분을 공략 (0:00 ~ 0:40)**

"D-CFG의 개념은 이해했지만, 여전히 경우의 수 폭발 문제가 남아있습니다. 우주에 있는 모든 모래알을 셀 수는 없으니까요. D-CFG는 이 문제를 어떻게 해결할까요? 핵심 전략은 **'전체 시퀀스를 한 번에 다루는 대신, 각 토큰(단어) 위치별로 문제를 나누어 해결하는 것'**입니다."

---

### **전략 1: 토큰별 분해 (Token-wise Decomposition) (0:40 ~ 1:30)**

"이것이 바로 **'토큰별 분해'**입니다. 이산 확산 모델은 이미지를 한 번에 그리는 대신, 픽셀 하나하나 또는 작은 영역을 점진적으로 복원하듯이, 텍스트도 단어 하나하나 또는 마스킹된 단어를 순차적으로 채워나가는 방식으로 작동합니다.

D-CFG는 이 특성을 활용합니다. 전체 문장 '나는 [MASK]를 좋아한다'에서 [MASK]에 들어갈 단어를 맞추는 것처럼, 각 위치에 어떤 단어가 올 확률이 높은지를 개별적으로 계산합니다. 이렇게 하면 10개의 단어로 된 문장의 모든 조합(10의 30제곱)을 고려하는 대신, 각 단어 위치마다 1,000개의 단어만 고려하면 됩니다.

이는 계산량을 상상할 수 없을 정도로 줄여줍니다. 마치 '전체 문장을 한 번에 맞춰봐!' 대신 '첫 번째 단어 힌트, 두 번째 단어 힌트...'처럼 단어별로 힌트를 주는 것과 같죠. 이 덕분에 조합 폭발 문제를 피하고 실제 계산이 가능한 수준이 됩니다."

---

### **전략 2: 확률 계산 및 가중치 적용 (1:30 ~ 1:50)**

"각 단어 위치에서, 우리는 두 가지 정보를 얻습니다. **'조건부 모델(Conditional Model)'**은 '긍정적인 문장'이라는 조건을 고려했을 때 각 단어가 올 확률을 알려주고, **'무조건부 모델(Unconditional Model)'**은 아무 조건 없이 그냥 각 단어가 올 확률을 알려줍니다.

D-CFG는 이 두 확률을 **'가이던스 강도 (Guidance Scale) γ'**라는 저울로 적절히 섞습니다. '긍정적인 문장'을 만들고 싶다면 조건부 모델의 의견에 더 무게를 싣는 식이죠. 이렇게 조합된 확률을 바탕으로 해당 위치에 올 단어를 최종적으로 선택합니다."

---

### **마무리: 효율적인 가이던스의 완성 (1:50 ~ 2:00)**

"이처럼 D-CFG는 '토큰별 분해'와 '확률 가중치 적용'이라는 두 가지 전략을 통해 이산 데이터에서도 효과적인 가이던스를 구현했습니다. 다음 장에서는 또 다른 접근 방식인 D-CBG에 대해 알아보겠습니다. D-CBG는 외부 전문가(분류기)의 도움을 받는 방식입니다."

# 슬라이드 14: 언어 모델링 성능 - 핵심 발견

**(슬라이드 전환 후 잠시 멈춤)**

---

### **슬라이드 소개 및 결과 분석의 중요성 (0:00 ~ 0:30)**

"앞선 슬라이드에서 언어 모델링 성능 비교 테이블을 보셨습니다. 단순히 숫자를 나열하는 것을 넘어, 이 결과들이 우리에게 어떤 중요한 의미를 갖는지, 핵심적인 발견들을 분석해 보겠습니다. 이 인사이트는 UDLM과 이산 확산 모델의 잠재력을 이해하는 데 매우 중요합니다."

---

### **발견 1: 어휘 크기의 영향 (0:30 ~ 1:10)**

"첫 번째 핵심 발견은 '어휘 크기의 영향'입니다. 결과 테이블에서 보셨듯이, UDLM은 어휘 크기가 작은 데이터셋(Species10, QM9)에서 특히 강점을 보였습니다. 이는 왜 그럴까요? 어휘 크기가 작으면 가능한 토큰의 종류가 적고, 시퀀스 조합의 복잡도도 상대적으로 낮아집니다. UDLM의 균등 노이즈 방식과 확률 기반 가이던스가 이러한 환경에서 더 효율적으로 탐색하고 최적의 시퀀스를 찾을 수 있기 때문으로 해석됩니다.

반대로 어휘 크기가 큰 데이터셋(Amazon, LM1B)에서는 아직 AR 모델이나 MDLM이 더 나은 성능을 보였습니다. 이는 UDLM이 대규모 어휘 환경에서 발생하는 더 큰 조합적 복잡성을 다루는 데 아직 개선의 여지가 있음을 시사합니다."

---

### **발견 2: 균등 노이즈의 재평가 및 연속 시간 효과 (1:10 ~ 1:50)**

"두 번째 중요한 발견은 '균등 노이즈 방식의 재평가'입니다. 기존에는 균등 노이즈 방식이 마스킹 방식보다 성능이 떨어진다는 인식이 있었습니다. 하지만 UDLM은 특정 조건에서 최고 성능을 달성하며 이러한 통념을 깼습니다.

이는 UDLM이 도입한 '연속 시간 ELBO'와 같은 수학적 개선 덕분입니다. 이론적인 분석을 통해 모델 학습의 목표를 더 명확하고 최적화하기 쉬운 형태로 만들었고, 이것이 실제 성능 혁신으로 이어진 것입니다. 수학적 엄밀성이 모델의 잠재력을 끌어올린 좋은 예시라고 할 수 있습니다."

---

### **실용적 의미 및 다음 슬라이드 예고 (1:50 ~ 2:00)**

"이러한 발견들은 분자, DNA 서열과 같이 어휘 크기가 제한적인 과학 도메인에서 이산 확산 모델이 강력한 도구가 될 수 있음을 시사합니다. 언어 모델링 외에 다른 이산 데이터에서의 가이던스 성능은 어떨까요? 다음 장에서는 게놈 및 분자 데이터에서의 가이던스 실험 결과를 살펴보겠습니다."

# 슬라이드 7: D-CFG: 분류기 없는 가이던스 - 개념

**(슬라이드 전환 후 잠시 멈춤)**

---

### **슬라이드 소개 및 D-CFG 개요 (0:00 ~ 0:40)**

"자, 이제 이 연구가 제안하는 첫 번째 가이던스 메커니즘인 'D-CFG', 즉 '이산 분류기 없는 가이던스(Discrete Classifier-Free Guidance)'의 개념을 살펴보겠습니다. 이름에서 알 수 있듯이, 이 방법은 별도의 분류기 모델 없이 확산 모델 자체만을 사용하여 가이던스를 수행합니다."

---

### **핵심 아이디어: 베이즈 규칙의 활용 (0:40 ~ 1:30)**

"D-CFG의 핵심 아이디어는 연속 데이터 가이던스에서 사용되는 분류기 없는 가이던스 기법을 이산 도메인에 맞게 재해석하는 것입니다. 이는 베이즈 규칙(Bayes' Rule)에 기반합니다. 연속 공간에서는 조건부 확률 p(z|y)의 기울기를 사용했지만, 이산 공간에서는 기울기 대신 확률 자체를 직접 다룹니다.

슬라이드 중앙에 있는 수식을 봐주세요. 이 수식은 가이던스가 적용된 확률 분포가 조건부 모델 p(z_s | y, z_t)와 무조건부 모델 p(z_s | z_t)의 확률을 가이던스 강도 γ(감마)로 가중 조합하여 얻어진다는 것을 보여줍니다. 여기서 z_t는 현재 확산 스텝에서의 데이터 상태, z_s는 이전 스텝(노이즈가 덜한 상태)의 데이터, y는 우리가 원하는 조건(예: 생성할 텍스트의 주제)입니다.

간단히 말해, '조건 y가 주어졌을 때의 확률'과 '조건 없이 그냥 생성될 확률' 사이의 비율을 활용하여, 조건 y에 더 잘 맞는 방향으로 생성 확률을 높여주는 방식입니다."

---

### **핵심 통찰 및 접근 방법 (1:30 ~ 1:50)**

"이 방법의 핵심 통찰은 '기울기 대신 확률 비율을 직접 계산한다'는 것입니다. 이산 공간에서는 미분이 어렵지만, 각 가능한 토큰 시퀀스에 대한 확률 값 자체는 모델로부터 얻을 수 있습니다. 따라서 이 확률 값들을 직접 조합하여 가이던스 효과를 내는 것이죠.

접근 방법은 조건부 모델과 무조건부 모델, 두 가지 버전의 확산 모델을 함께 학습시킨 후, 생성 단계에서 이 두 모델의 예측 확률을 γ 값으로 적절히 섞어 최종 샘플링 확률을 결정하는 것입니다."

---

### **다음 슬라이드 예고 (1:50 ~ 2:00)**

"개념은 이해되셨을 텐데요, 그렇다면 이 D-CFG가 이산 데이터의 조합 폭발 문제를 어떻게 회피하고 실제로 구현되는지, 다음 장에서 더 구체적인 구현 방법을 살펴보겠습니다."

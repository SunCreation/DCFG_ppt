# 슬라이드 10: D-CBG: 전문가 활용, 똑똑하게 하기

**(슬라이드 전환 후 잠시 멈춤)**

---

### **문제 제기: 전문가 활용의 대가 (0:00 ~ 0:30)**

"D-CBG는 외부 분류기라는 전문가의 도움을 받아 유연한 가이던스를 제공합니다. 하지만 이 전문가에게 계속 질문하는 것이 생각보다 비용이 많이 듭니다. 어떻게 하면 이 비용을 줄이고 효율적으로 전문가의 지식을 활용할 수 있을까요?"

---

### **기본 구현: 모든 가능성 질문하기 (0:30 ~ 1:15)**

"D-CBG의 가장 기본적인 구현 방법은 이렇습니다. 문장을 만들어가는 각 단계에서, 우리는 특정 단어 위치에 들어갈 수 있는 **'모든 가능한 단어'**를 하나씩 넣어봅니다. 그리고 단어가 바뀔 때마다 **'외부 분류기 심사위원'**에게 물어봅니다. '이 단어를 넣으면 원하는 조건에 얼마나 잘 맞나요?'

만약 어휘에 1,000개의 단어가 있고 문장 길이가 100이라면, 한 단계에서 한 단어 위치를 바꿀 때마다 1,000번의 질문을 해야 합니다. 문장 전체를 고려하면 이 질문 횟수는 엄청나게 늘어납니다. 마치 모든 가능한 경로를 일일이 다 걸어보고 목적지에 얼마나 가까워지는지 확인하는 것처럼 비효율적입니다."

---

### **핵심 최적화: Taylor 근사 활용 (1:15 ~ 1:50)**

"이 비효율성을 해결하기 위해 연구진은 **'Taylor 근사(Taylor Approximation)'**라는 수학적 기법을 활용했습니다. 이 용어가 어렵게 느껴진다면, 이렇게 생각해보세요. **'모든 가능성을 다 해보지 않고도, 작은 변화가 전체 결과에 미치는 영향을 예측하는 방법'**입니다.

심사위원(분류기)에게 모든 단어를 다 물어보는 대신, 현재 문장에 대한 심사위원의 점수와, 각 단어 위치가 점수에 얼마나 민감하게 반응하는지(일종의 '영향력' 또는 '기울기' 정보)를 파악합니다. 그리고 이 정보를 바탕으로 '만약 이 단어를 저 단어로 바꾸면 점수가 대략 이만큼 변하겠구나' 하고 예측하는 것입니다.

이 예측은 정확한 계산은 아니지만, 대부분의 경우 충분히 유용하며, 모든 단어를 일일이 시도하는 것보다 훨씬 빠릅니다. 이 최적화 덕분에 D-CBG는 계산 비용을 획기적으로 줄여 실제 적용 가능한 수준이 되었습니다."

---

### **마무리: 효율적인 전문가 시스템 (1:50 ~ 2:00)**

"결론적으로 D-CBG는 외부 분류기의 전문성을 활용하되, Taylor 근사라는 똑똑한 예측 기법을 통해 효율성까지 확보했습니다. 하지만 아무리 가이던스 기법이 좋아도, 기반이 되는 확산 모델 자체의 성능도 중요합니다. 다음 장에서는 이 연구에서 제안하는 새로운 확산 모델 아키텍처인 UDLM에 대해 알아보겠습니다."
